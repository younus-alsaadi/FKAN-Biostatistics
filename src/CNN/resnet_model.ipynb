{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg4vT1BWLTD7",
        "outputId": "072c6caa-8b1f-4d99-c544-14ecdf964cbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT4iG--NOpTw",
        "outputId": "9da41fdb-deca-42ac-9a54-360016c7fc1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['PNEUMONIA', 'NORMAL']\n",
        "img_size = 224\n",
        "\n",
        "def get_training_data(data_dir):\n",
        "    data = []\n",
        "\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            try:\n",
        "                # Load and resize the image\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))  # Resize the image\n",
        "\n",
        "                # Add the image and label as a pair\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img}: {e}\")\n",
        "\n",
        "    # Convert the list to a NumPy array\n",
        "    data = np.array(data, dtype=object)  # Use dtype=object to allow image-label pairing\n",
        "    return data\n",
        "\n",
        "# Load the data\n",
        "train_data = get_training_data('/content/drive/MyDrive/chest_xray/train')\n",
        "test_data = get_training_data('/content/drive/MyDrive/chest_xray/test')\n",
        "val_data = get_training_data('/content/drive/MyDrive/chest_xray/val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11680mFSNiEV",
        "outputId": "6650f38a-c94f-4c88-9d51-12d855984734"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3107/3107 [01:07<00:00, 45.82it/s]\n",
            "100%|██████████| 3107/3107 [01:44<00:00, 29.77it/s]\n",
            "100%|██████████| 390/390 [00:04<00:00, 83.81it/s] \n",
            "100%|██████████| 234/234 [00:04<00:00, 54.60it/s]\n",
            "100%|██████████| 776/776 [00:11<00:00, 65.93it/s] \n",
            "100%|██████████| 270/270 [00:07<00:00, 38.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to normalize the images\n",
        "def normalize_images(data):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for img, label in tqdm(data):\n",
        "        # Normalization: each pixel is divided by 255\n",
        "        normalized_img = img / 255.0\n",
        "        images.append(normalized_img)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Convert the images and labels into separate arrays\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Normalize the images in the training dataset\n",
        "train_images, train_labels = normalize_images(train_data)\n",
        "val_images, val_labels = normalize_images(val_data)\n",
        "test_images, test_labels = normalize_images(test_data)\n",
        "\n",
        "\n",
        "# Check the shape and an example of the normalized and shuffled data\n",
        "print(f\"Shape of normalized and shuffled train images: {train_images.shape}\")\n",
        "print(f\"Shape of normalized and shuffled validation images: {val_images.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrf_UaBJOHyK",
        "outputId": "4252c3db-2e24-435b-fc40-f89cdc568c90"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6214/6214 [00:01<00:00, 3225.26it/s]\n",
            "100%|██████████| 1046/1046 [00:00<00:00, 8878.38it/s]\n",
            "100%|██████████| 624/624 [00:00<00:00, 10790.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of normalized and shuffled train images: (6214, 224, 224)\n",
            "Shape of normalized and shuffled validation images: (1046, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes=2, softmax=True):\n",
        "      super(ResNet, self).__init__()\n",
        "      self.resnet = torchvision.models.resnet50(pretrained=True)\n",
        "      num_ftrs = self.resnet.fc.out_features\n",
        "      self.fc = nn.Linear(num_ftrs, num_classes)\n",
        "      self.bn = nn.BatchNorm1d(num_ftrs)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.softmax = torch.nn.Softmax(dim=1) if softmax else None\n",
        "      self.change_conv1()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.resnet(x)\n",
        "      x = self.bn(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.fc(x)\n",
        "      if self.softmax:\n",
        "        x = self.softmax(x)\n",
        "      return x\n",
        "\n",
        "    def change_conv1(self):\n",
        "      original_conv1 = self.resnet.conv1\n",
        "\n",
        "      #Create a new convolutional layer with 1 input channel instead of 3\n",
        "      new_conv1 = nn.Conv2d(\n",
        "        in_channels=1,  # Grayscale has 1 channel\n",
        "        out_channels=original_conv1.out_channels,\n",
        "        kernel_size=original_conv1.kernel_size,\n",
        "        stride=original_conv1.stride,\n",
        "        padding=original_conv1.padding,\n",
        "        bias=original_conv1.bias is not None\n",
        ")\n",
        "\n",
        "      # Initialize the new conv layer's weights by averaging the RGB weights\n",
        "      with torch.no_grad():\n",
        "        new_conv1.weight = nn.Parameter(original_conv1.weight.mean(dim=1, keepdim=True))\n",
        "\n",
        "        #Replace the original conv1 with the new one\n",
        "        self.resnet.conv1 = new_conv1\n",
        "\n",
        "\n",
        "model = ResNet(num_classes=2, softmax=True)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print(device)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhWclu08OZ6l",
        "outputId": "d5073850-3e5b-4686-fe54-830306e58ab2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Convert the images and labels to PyTorch tensors\n",
        "\n",
        "# Apply the transformation to training and validation images\n",
        "train_images_tensor = torch.stack([torch.tensor(img, dtype=torch.float) for img in train_images]).unsqueeze(1)\n",
        "val_images_tensor = torch.stack([torch.tensor(img, dtype=torch.float) for img in val_images]).unsqueeze(1)\n",
        "\n",
        "# Now permute them\n",
        "train_images_tensor = train_images_tensor.permute(0, 1, 2, 3)  # (N, 1, 244, 244)\n",
        "val_images_tensor = val_images_tensor.permute(0, 1, 2, 3)      # (N, 1, 244, 244)\n",
        "print(val_images_tensor.shape, train_images_tensor.shape)\n",
        "\n",
        "# The tensors are now in the shape (N, 1, 244, 244), where N is the number of images\n",
        "\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
        "val_labels_tensor = torch.tensor(val_labels, dtype=torch.long)\n",
        "\n",
        "# Create the dataset and DataLoader\n",
        "train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
        "val_dataset = TensorDataset(val_images_tensor, val_labels_tensor)\n",
        "\n",
        "# Define the batch size\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "print('Done!')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDehAi3WS1xR",
        "outputId": "aae09fa0-0ab0-4ec3-c85c-df303a05980d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1046, 1, 224, 224]) torch.Size([6214, 1, 224, 224])\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**"
      ],
      "metadata": {
        "id": "_wCqaba_Xu59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "criterion = nn.CrossEntropyLoss()  # For multi-class or binary classification\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)  # AdamW with L2 regularization\n",
        "\n",
        "# Now the data is ready for training and validation\n",
        "\n",
        "# Function to calculate relevant metrics\n",
        "\n",
        "# Training function with Early Stopping\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10):\n",
        "    patience_counter = 0\n",
        "    best_validation_score = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        p_bar = tqdm(train_loader)\n",
        "        running_loss = 0\n",
        "\n",
        "        for i, (images, labels) in enumerate(p_bar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            p_bar.set_description(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss / (i + 1)}\")\n",
        "\n",
        "\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            model.eval()\n",
        "            p_bar = tqdm(val_loader)\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            with torch.no_grad():\n",
        "                for i, (images, labels) in enumerate(p_bar):\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    p_bar.set_description(f'Epoch {epoch+1}/{num_epochs} - Validation Batch: {i}')\n",
        "\n",
        "            class_report = classification_report(all_labels, all_preds, target_names=['Pneumonia', 'Normal'], output_dict=True)\n",
        "            validation_accuracy = class_report['accuracy']\n",
        "            validation_f1_score = class_report['weighted avg']['f1-score']\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs} - Validation Accuracy: {validation_accuracy} - Validation F1 Score: {validation_f1_score:.4f}\")\n",
        "            if validation_f1_score > best_validation_score:\n",
        "                best_validation_score = validation_f1_score\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), os.path.join('/content/drive/MyDrive/model_results', 'best_model_resnet.pth'))\n",
        "\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "# Start training\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100, patience=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "oGlRJ8QtTziF",
        "outputId": "f22a306c-2bb0-4668-a84f-53b8a3ba7855"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 - Loss: 0.38104544236699894: 100%|██████████| 777/777 [01:18<00:00,  9.90it/s]\n",
            "Epoch 2/100 - Loss: 0.35201236333319275: 100%|██████████| 777/777 [01:16<00:00, 10.12it/s]\n",
            "Epoch 2/100 - Validation Batch: 130: 100%|██████████| 131/131 [00:04<00:00, 32.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 - Validation Accuracy: 0.9722753346080306 - Validation F1 Score: 0.9727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100 - Loss: 0.33707662362082735: 100%|██████████| 777/777 [01:16<00:00, 10.15it/s]\n",
            "Epoch 4/100 - Loss: 0.3404322650518503: 100%|██████████| 777/777 [01:16<00:00, 10.16it/s]\n",
            "Epoch 4/100 - Validation Batch: 130: 100%|██████████| 131/131 [00:03<00:00, 33.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 - Validation Accuracy: 0.9617590822179732 - Validation F1 Score: 0.9625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100 - Loss: 0.3433035740214118: 100%|██████████| 777/777 [01:16<00:00, 10.13it/s]\n",
            "Epoch 6/100 - Loss: 0.34204173176291675: 100%|██████████| 777/777 [01:16<00:00, 10.16it/s]\n",
            "Epoch 6/100 - Validation Batch: 130: 100%|██████████| 131/131 [00:03<00:00, 32.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 - Validation Accuracy: 0.9674952198852772 - Validation F1 Score: 0.9681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100 - Loss: 0.33465545426004184: 100%|██████████| 777/777 [01:16<00:00, 10.16it/s]\n",
            "Epoch 8/100 - Loss: 0.340424232079409: 100%|██████████| 777/777 [01:16<00:00, 10.16it/s]\n",
            "Epoch 8/100 - Validation Batch: 130: 100%|██████████| 131/131 [00:03<00:00, 33.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 - Validation Accuracy: 0.9847036328871893 - Validation F1 Score: 0.9848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100 - Loss: 0.33238210767852755: 100%|██████████| 777/777 [01:16<00:00, 10.12it/s]\n",
            "Epoch 10/100 - Loss: 0.3375673053961156: 100%|██████████| 777/777 [01:16<00:00, 10.15it/s]\n",
            "Epoch 10/100 - Validation Batch: 130: 100%|██████████| 131/131 [00:03<00:00, 33.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 - Validation Accuracy: 0.988527724665392 - Validation F1 Score: 0.9885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100 - Loss: 0.3325234763180427: 100%|██████████| 777/777 [01:17<00:00, 10.09it/s]\n",
            "Epoch 12/100 - Loss: 0.3296274316893888: 100%|██████████| 777/777 [01:18<00:00,  9.86it/s]\n",
            "Epoch 12/100 - Validation Batch: 130: 100%|██████████| 131/131 [00:03<00:00, 34.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 - Validation Accuracy: 0.9101338432122371 - Validation F1 Score: 0.9139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100 - Loss: 0.33417184561935825:  17%|█▋        | 134/777 [00:13<01:03, 10.07it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-24dae8f62d25>\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-24dae8f62d25>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mp_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss / (i + 1)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing**"
      ],
      "metadata": {
        "id": "FZ-Sw9n_Xoxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('/content/drive/MyDrive/model_results/best_model_resnet.pth')\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aW6M8ESPYt7f",
        "outputId": "40b038d1-7ec6-4103-cfc7-c9c50afbcef5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-5e523879719c>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('/content/drive/MyDrive/model_results/best_model_resnet.pth')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_tensor = torch.stack([torch.tensor(img, dtype=torch.float) for img in test_images]).unsqueeze(1)  # Applying the same transformation as for train/val\n",
        "test_images_tensor = test_images_tensor.permute(0, 1, 2, 3)\n",
        "print(test_images_tensor.shape)\n",
        "\n",
        "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)  # or torch.float if binary classification\n",
        "\n",
        "# Create the dataset and DataLoader for the test set\n",
        "test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "for images, labels in test_loader:\n",
        "  images, labels = images.to(device), labels\n",
        "  outputs = model(images)\n",
        "  _, preds = torch.max(outputs, 1)\n",
        "  all_predictions.extend(preds.cpu().numpy())\n",
        "  all_labels.extend(labels.numpy())\n",
        "\n",
        "class_report = classification_report(all_labels, all_predictions, target_names=['Pneumonia', 'Normal'])\n",
        "print(class_report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAvunQT-Xtwx",
        "outputId": "81c71b55-645c-4d78-eb34-ed697dad9e35"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([624, 1, 224, 224])\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Pneumonia       0.89      0.96      0.93       390\n",
            "      Normal       0.93      0.81      0.86       234\n",
            "\n",
            "    accuracy                           0.91       624\n",
            "   macro avg       0.91      0.89      0.90       624\n",
            "weighted avg       0.91      0.91      0.90       624\n",
            "\n"
          ]
        }
      ]
    }
  ]
}